{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 177\u001b[0m\n\u001b[1;32m    173\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    175\u001b[0m frames_between \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# How many frames between frames?\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_between\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 98\u001b[0m, in \u001b[0;36mprocess_video\u001b[0;34m(video_path, output_path, ground_truth_df, frame_rate)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Apply background subtraction\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m fgMask \u001b[38;5;241m=\u001b[39m \u001b[43mbackSub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Find contours\u001b[39;00m\n\u001b[1;32m    101\u001b[0m contours, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(\n\u001b[1;32m    102\u001b[0m     fgMask\u001b[38;5;241m.\u001b[39mcopy(), cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "\n",
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=50):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = {}\n",
    "        self.disappeared = {}\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        if len(rects) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            return self.objects\n",
    "\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        else:\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            for row in unusedRows:\n",
    "                objectID = objectIDs[row]\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            for col in unusedCols:\n",
    "                self.register(inputCentroids[col])\n",
    "\n",
    "        return self.objects\n",
    "\n",
    "\n",
    "def process_video(video_path, output_path, ground_truth_df, frame_rate):\n",
    "    # Initialize the background subtractor and centroid tracker\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "    ct = CentroidTracker()\n",
    "\n",
    "    # Open the video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = None\n",
    "\n",
    "    frame_id = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fgMask = backSub.apply(frame)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(\n",
    "            fgMask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        rects = []\n",
    "\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 500:\n",
    "                continue\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            rects.append((x, y, x + w, y + h))\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        objects = ct.update(rects)\n",
    "\n",
    "        for (objectID, centroid) in objects.items():\n",
    "            text = \"ID {}\".format(objectID)\n",
    "            cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "\n",
    "        # Initialize the video writer if not already initialized\n",
    "        if out is None:\n",
    "            out = cv2.VideoWriter(output_path, fourcc, cap.get(\n",
    "                cv2.CAP_PROP_FPS), (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        current_frame_truth = ground_truth_df[ground_truth_df['FrameID'] == frame_id]\n",
    "\n",
    "        for index, row in current_frame_truth.iterrows():\n",
    "            ped_id = row['PedID']\n",
    "            pos_x = row['PosX']\n",
    "            pos_y = row['PosY']\n",
    "            cv2.circle(frame, (int(pos_x), int(pos_y)), 4, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"GT {ped_id}\", (int(pos_x) - 10, int(pos_y) - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        frame_id += frames_between\n",
    "\n",
    "    cap.release()\n",
    "    if out:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Directory containing the dataset and ground truth\n",
    "dataset_dir = 'UCY_dataset'\n",
    "ground_truth_file = 'Final_data_zara02.csv'\n",
    "output_dir = 'processed_videos'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load ground truth data\n",
    "column_names = [\"FrameID\", \"PedID\", \"PosX\", \"PosY\"]\n",
    "ground_truth_df = pd.read_csv(os.path.join(\n",
    "    dataset_dir, ground_truth_file), names=column_names)\n",
    "\n",
    "# Process each video file in the dataset directory\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith('.avi'):\n",
    "        video_path = os.path.join(dataset_dir, filename)\n",
    "        # filename.split(\".\")[0]\n",
    "        output_path = os.path.join(\n",
    "            output_dir, filename.split('.')[0]+\"_processed.mp4\")\n",
    "\n",
    "        # Check if the file already exists and modify name accordingly\n",
    "\n",
    "        counter = 1\n",
    "        while os.path.exists(output_path):\n",
    "            output_path = os.path.join(\n",
    "                output_dir, f\"{filename.split('.')[0]}_processed_{counter}.mp4\")\n",
    "            counter += 1\n",
    "\n",
    "        frames_between = 10  # How many frames between frames?\n",
    "\n",
    "        process_video(video_path, output_path, ground_truth_df, frames_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
